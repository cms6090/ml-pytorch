{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 : 다차원 배열을 나타내는 자료형(넘파이의 ndarray)\n",
    "\n",
    "<code>torch.tensor(data, dtype=None, device=None, requires_grad=False)</code>\n",
    "\n",
    "- data : 텐서로 변환하고자 하는 데이터(파이썬 리스트, 넘파이 배열 등)\n",
    "- dtype(optional) : 텐서의 데이터 타입, 기본값은 None, 자동으로 데이터 타입 인식\n",
    "- device(optional) : 텐서가 사용될 디바이스, 기본값은 None, CPU 상에서 계산\n",
    "- requires_grad(optional) : 해당 텐서가 그래디언트를 계산할지 여부, 기본값은 False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = [[1,2,3], [4,5,6]]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) \n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(data)\n",
    "y = torch.tensor(data, dtype=torch.float32)\n",
    "print(x, \"\\n\", y)\n",
    "\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1차원 텐서 생성\n",
    "x = torch.tensor([1,2,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 2차원 텐서 생성\n",
    "y = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# 모든 원소가 0인 3차원 텐서 생성\n",
    "z = torch.zeros((2,3,4)) \n",
    "# 2 : 첫번째 차원의 크기 -> 2개의 3차원 행렬\n",
    "# 3 : 두번째 차원의 크기 -> 3개의 행\n",
    "# 4 : 세번째 차원의 크기 -> 4개의 열\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "# 모든 원소가 1인 4차원 텐서 생성\n",
    "w = torch.ones((2,2,2,2))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6781, 0.8560, 0.1398],\n",
      "        [0.7436, 0.3452, 0.5643],\n",
      "        [0.7180, 0.2606, 0.6531]])\n"
     ]
    }
   ],
   "source": [
    "# 랜덤한 값으로 채워진 3x3 텐서 생성\n",
    "r = torch.rand((3,3))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 분포에서 난수 생성\n",
    "- rand : 균등분포(0,1)에서 난수 생성\n",
    "- randn : 정규분포(0,1)에서 난수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4874, 0.7650, 0.0589],\n",
      "        [0.9882, 0.6390, 0.6067]])\n"
     ]
    }
   ],
   "source": [
    "# 균등 분포(0,1)에서 난수를 생성\n",
    "x = torch.rand(2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5322, -1.8572,  0.5014],\n",
      "        [ 0.0211,  0.0680, -2.3845]])\n"
     ]
    }
   ],
   "source": [
    "# 정규 분포(0,1)에서 난수를 생성\n",
    "y = torch.randn(2,3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 메모리 상에 할당된 임의의 값으로 초기화된 텐서를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# .Tensor 예제1\n",
    "a = torch.tensor([1,2,3])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# .empty 예제\n",
    "b = torch.empty(2,3)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# .Tensor 예제2\n",
    "c = torch.Tensor(2,3)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### .from_numpy()와 .tensor()의 차이\n",
    "- .from_numpy() : NumPy 배열을 Pytorch Tensor로 변환<br>기존 NumPy 배열과 데이터를 공유 -> 반환된 Tensor를 수정하면 NumPy 배열도 수정(동일 위치 참조)\n",
    "- .tensor() : NumPy 배열과 유사한 새로운 Pytorch Tensor를 생성<br>새로운 Tensor와 NumPy 배열은 데이터 공유 X -> Tensor를 수정해도 NumPy 배열은 변경X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  2  3]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# NumPy 배열 생성\n",
    "a_np = np.array([1,2,3])\n",
    "\n",
    "# NumPy 배열을 Pytorch Tensor로 변환\n",
    "a_tensor = torch.from_numpy(a_np)\n",
    "\n",
    "# Tensor 수정\n",
    "a_tensor[0] = -1\n",
    "\n",
    "print(a_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# NumPy 배열 생성\n",
    "a_np = np.array([1,2,3])\n",
    "\n",
    "# NumPy 배열을 Pytorch Tensor로 변환\n",
    "a_tensor = torch.tensor(a_np)\n",
    "\n",
    "# Tensor 수정\n",
    "a_tensor[0] = -1\n",
    "\n",
    "print(a_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### torch.randn : 정규 분포에서 무작위로 추출한 난수를 가지고 지정된 크기의 텐서를 생성\n",
    "<code>torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor</code>\n",
    "- *size : 생성하려는 텐서의 크기를 나타내는 가변 인수<br>\n",
    "ex) torch.rand(3,4)는 3x4크기의 2차원 텐서 생성\n",
    "- out(optional) : 결과를 저장할 출력 텐서, 기본값은 None\n",
    "- dtype(optional) : 생성되는 텐서의 데이터 타입을 지정하는 인수, 기본값은 None\n",
    "- layout(optional) : 생성되는 텐서의 레이아웃을 지정하는 인수, 기본값은 torch.strided\n",
    "- device(optional) : 생성되는 텐서의 디바이스를 지정하는 인수, 기본값은 None, 현재 사용 중인 디바이스로 자동 설정\n",
    "- requires_grad(optional) : 생성되는 텐서의 기울기를 계산할 지 여부를 지정하는 인수, 기본값은 False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6051, -0.0490,  1.1763],\n",
      "        [ 0.0181, -0.4252,  0.4442]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 2x3 크기의 텐서 생성\n",
    "tensor = torch.randn(2, 3)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2179,  2.2671,  2.3802,  3.1352],\n",
      "        [ 0.0160, -1.0280,  4.2760,  3.7700],\n",
      "        [ 0.7445,  1.7273,  1.8676,  0.2182]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 평균을 2, 표준편차를 1.5로 바꾸로 싶은 경우\n",
    "mean = 2\n",
    "std = 1.5\n",
    "size = (3,4) # 원하는 사이즈 지정\n",
    "\n",
    "# 평균이 2이고 표준 편차가 1.5인 정규분포에서 무작위로 샘플 생성\n",
    "samples = torch.randn(size) * std + mean\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 파이토치 텐서의 속성\n",
    "<ul>\n",
    "<li>데이터 타입(dtype)\n",
    "<ul>\n",
    "<li>torch.FloatTensor : 32비트 부동소수점 저장</li>\n",
    "<li>torch.LongTensr : 64비트 정수를 저장</li>\n",
    "</ul></li>\n",
    "<li>디바이스(device) : 텐서가 저장되는 장치(CPU/GPU)</li>\n",
    "<li>크기(size) : 텐서 안에 있는 데이터의 개수\n",
    "<ul><li>torch.Size([3,4]) : 3행 4열의 행렬</li></ul></li>\n",
    "<li>모양(shape) : 텐서의 차원</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cpu\n",
      "3\n",
      "torch.Size([3, 2]) torch.Size([3, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 데이터 타입\n",
    "x = torch.tensor([1,2,3])\n",
    "print(x.dtype) # 기본값 : torch.int64(int의 경우), torch.float32(float의 경우)\n",
    "\n",
    "# 디바이스\n",
    "device = torch.device('cpu')\n",
    "x = torch.tensor([1,2,3], device = device)\n",
    "print(x.device) # CPU\n",
    "\n",
    "# 크기\n",
    "x = torch.tensor([1,2,3])\n",
    "print(x.numel()) # .numel() : 크기 출력\n",
    "\n",
    "# 모양\n",
    "x = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print(x.shape, x.size())\n",
    "\n",
    "# 모양 변경\n",
    "x = torch.tensor([1,2,3,4])\n",
    "y = x.view(2,2) # x.reshape(2,2)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]]) tensor([[5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "tensor([[-4, -4],\n",
      "        [-4, -4]])\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor(11)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 텐서 생성\n",
    "a = torch.tensor([[1,2],[3,4]])\n",
    "b = torch.tensor([[5,6],[7,8]])\n",
    "\n",
    "print(a,b)\n",
    "# 덧셈\n",
    "c = a + b\n",
    "print(c)\n",
    "\n",
    "# 뺌셈\n",
    "d = a - b\n",
    "print(d)\n",
    "\n",
    "# 곱셈\n",
    "e = a * b\n",
    "print(e)\n",
    "\n",
    "# 나눗셈\n",
    "f = a / b\n",
    "print(f)\n",
    "\n",
    "# 행렬곱\n",
    "g = torch.mm(a,b)\n",
    "print(g)\n",
    "\n",
    "# 점곱\n",
    "h = torch.dot(torch.tensor([1,2]), torch.tensor([3,4])) # x^T * y\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3],\n",
      "        [3, 4]])\n",
      "tensor([4, 6])\n",
      "tensor([[1, 3],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "# 요소별 최대값 계산\n",
    "i = torch.tensor([[1,2],[3,4]])\n",
    "j = torch.tensor([[4,3],[2,1]])\n",
    "k = torch.max(i, j)\n",
    "print(k)\n",
    "\n",
    "# 차원 축소\n",
    "l = torch.tensor([[1,2],[3,4]])\n",
    "m = torch.sum(l, dim=0)\n",
    "print(m)\n",
    "\n",
    "# 전치\n",
    "n = torch.tensor([[1,2],[3,4]])\n",
    "o = torch.transpose(n, 0, 1)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor([[1, 2],\n",
      "        [4, 5],\n",
      "        [7, 8]])\n",
      "tensor([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 인덱싱\n",
    "p = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "q = p[1,0]\n",
    "print(q)\n",
    "\n",
    "# 슬라이싱\n",
    "r = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "s = r[:, :2]\n",
    "print(s)\n",
    "\n",
    "# 조건부 인덱싱\n",
    "t = torch.tensor([1,2,3,4,5])\n",
    "u = t[t > 3]\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 텐서의 차원을 변경하는 연산\n",
    "- unsqueeze() : 지정된 차원에 1인 차원 추가\n",
    "- squeeze() : 크기가 1인 차원 제거\n",
    "- reshape() : 텐서의 형태 변환\n",
    "- sort() : 텐서의 요소 정렬, 정렬된 텐서와 원래 인덱스 반환\n",
    "- argsort() : 텐서의 요소를 정렬했을 때의 인덱스를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4]) torch.Size([4])\n",
      "tensor([[1, 2, 3, 4]]) torch.Size([1, 4])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]]) torch.Size([4, 1])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]) torch.Size([2, 2])\n",
      "tensor([1, 2, 3]) tensor([2, 1, 0])\n",
      "tensor([4, 5, 6]) tensor([0, 1, 2])\n",
      "tensor([3, 2, 1]) tensor([2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 텐서 생성\n",
    "x = torch.tensor([1,2,3,4])\n",
    "print(x, x.shape)\n",
    "\n",
    "# 텐서 차원 변경\n",
    "y = x.unsqueeze(0) # 첫 번째 차원에 1 추가\n",
    "print(y, y.shape)\n",
    "\n",
    "y = x.unsqueeze(1)\n",
    "print(y, y.shape)\n",
    "\n",
    "# 텐서 reshape\n",
    "y = x.reshape(2,2)\n",
    "print(y, y.shape)\n",
    "\n",
    "# 텐서 정렬\n",
    "x = torch.tensor([3,2,1])\n",
    "y = torch.tensor([4,5,6])\n",
    "z = torch.tensor([1,2,3])\n",
    "a, b = torch.sort(x)\n",
    "print(a, b)\n",
    "\n",
    "a, b = torch.sort(y)\n",
    "print(a, b)\n",
    "\n",
    "a, b = torch.sort(z, descending = True)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]] \n",
      " [[5 6]\n",
      " [7 8]] \n",
      "\n",
      "[[1 2 5 6]\n",
      " [3 4 7 8]]\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "[[1 2 5 6]\n",
      " [3 4 7 8]]\n"
     ]
    }
   ],
   "source": [
    "# numpy\n",
    "arr1 = np.array([[1,2],[3,4]])\n",
    "arr2 = np.array([[5,6],[7,8]])\n",
    "print(arr1, \"\\n\", arr2, \"\\n\")\n",
    "print(np.concatenate((arr1, arr2), axis=1))\n",
    "print(np.vstack((arr1, arr2)))\n",
    "print(np.hstack((arr1, arr2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# tensor\n",
    "a1 = torch.tensor(arr1)\n",
    "a2 = torch.tensor(arr2)\n",
    "print(torch.cat((a1, a2), axis=1))\n",
    "print(torch.vstack((a1,a2))) # 세로로 병합\n",
    "print(torch.hstack((a1,a2))) # 가로로 병합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 유용한 함수들\n",
    "<ul>\n",
    "<li> torch.eq : 2개의 입력 텐서를 받아 같은 모양(shape)의 텐서를 반환<br>\n",
    "두 텐서의 원소 간의 동등성을 비교하여 값(True/False)로 채워진 텐서를 반환</li>\n",
    "<br>\n",
    "<li> torch.softmax : 입력값을 확률 형태로 변환해주는 함수<br>\n",
    "<code>torch.softmax(input, dim=None, dtype=None)</code></li>\n",
    "<ul>\n",
    "    <li>input : 소프트맥스 함수를 적용하려는 입력 텐서</li>\n",
    "    <li>dim(optional) : 소프트맥스를 계산할 차원, 기본값은 None, 마지막 차원이 사용</li>\n",
    "    <li>dtype(optional) : 출력 센서의 데이터타입, 기본값은 None</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True])\n",
      "tensor([ True,  True, False])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([1, 2, 3])\n",
    "c = torch.tensor([1, 2, 4])\n",
    "\n",
    "result1 = torch.eq(a, b)\n",
    "result2 = torch.eq(a, c)\n",
    "\n",
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 2.0, 3.0]) # 입력 텐서\n",
    "softmax_output = torch.softmax(a, dim=0) # dim=0으로 소프트맥스 계산\n",
    "print(softmax_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 인플레이스 연산 : 원본 텐서의 값을 변경 -> 메모리를 절약\n",
    "- add_\n",
    "- sub_\n",
    "- mul_\n",
    "- div_\n",
    "- pow_\n",
    "- sqrt_\n",
    "- round_\n",
    "- floor_\n",
    "- ceil_\n",
    "- clamp_\n",
    "- fill_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 4])\n",
      "tensor([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 인플레이스 연산 예제\n",
    "a = torch.tensor([1,2,3])\n",
    "b = a # 동일한 메모리 주소 참조 -> 하나가 변경되면 나머지도 변경\n",
    "a.add_(torch.tensor([1,1,1]))\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .fill_() : 텐서의 모든 요소를 지정된 값으로 새로운 텐서를 생성\n",
    "- .full() : 주어진 크기와 지정된 값으로 새로운 텐서를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 3x3 크기의 텐서 생성\n",
    "x = torch.zeros(3,3)\n",
    "print(x)\n",
    "\n",
    "# 모든 요소를 1로 채우기\n",
    "x.fill_(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 5, 5],\n",
      "        [5, 5, 5],\n",
      "        [5, 5, 5]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 3x3 크기의 텐서를 5로 채우기\n",
    "x = torch.full((3,3), 5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# GPU가 존재하면 텐서를 이동\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")\n",
    "    print(\"GPU 사용\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 초기화\n",
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got list)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m x_np \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np_array)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_np)\n\u001b[1;32m----> 8\u001b[0m y_np \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# data가 numpy가 아님\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected np.ndarray (got list)"
     ]
    }
   ],
   "source": [
    "# NumPy 배열로부터 생성\n",
    "np_array = np.array(data)\n",
    "print(np_array)\n",
    "\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)\n",
    "\n",
    "y_np = torch.from_numpy(data) # data가 numpy가 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor : \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Ones Tensor : \n",
      " tensor([[0.1298, 0.7463],\n",
      "        [0.3321, 0.4177]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 다른 텐서로부터 생성하기\n",
    "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지\n",
    "print(f\"Ones Tensor : \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # x_data의 속성을 덮어씀\n",
    "print(f\"Ones Tensor : \\n {x_rand} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.0966, 0.1644, 0.5869],\n",
      "        [0.6003, 0.4327, 0.1046]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 무작위 또는 상수 값 사용\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4690, 0.6381, 0.2164, 0.6478],\n",
      "        [0.4785, 0.6251, 0.0216, 0.5551],\n",
      "        [0.6705, 0.8115, 0.8394, 0.8590]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# 텐서의 속성\n",
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(tensor)\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2240, 0.1235, 0.9753, 0.1161],\n",
      "        [0.3348, 0.5936, 0.0995, 0.0501],\n",
      "        [0.0473, 0.6618, 0.1144, 0.5100],\n",
      "        [0.0258, 0.9578, 0.3849, 0.1836]]) \n",
      "\n",
      "First row: tensor([0.2240, 0.1235, 0.9753, 0.1161])\n",
      "First column: tensor([0.2240, 0.3348, 0.0473, 0.0258])\n",
      "Last column: tensor([0.1161, 0.0501, 0.5100, 0.1836])\n",
      "tensor([[0.2240, 0.0000, 0.9753, 0.1161],\n",
      "        [0.3348, 0.0000, 0.0995, 0.0501],\n",
      "        [0.0473, 0.0000, 0.1144, 0.5100],\n",
      "        [0.0258, 0.0000, 0.3849, 0.1836]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 연산\n",
    "tensor = torch.rand(4,4)\n",
    "print(tensor, \"\\n\")\n",
    "\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2240, 0.0000, 0.9753, 0.1161, 0.2240, 0.0000, 0.9753, 0.1161, 0.2240,\n",
      "         0.0000, 0.9753, 0.1161],\n",
      "        [0.3348, 0.0000, 0.0995, 0.0501, 0.3348, 0.0000, 0.0995, 0.0501, 0.3348,\n",
      "         0.0000, 0.0995, 0.0501],\n",
      "        [0.0473, 0.0000, 0.1144, 0.5100, 0.0473, 0.0000, 0.1144, 0.5100, 0.0473,\n",
      "         0.0000, 0.1144, 0.5100],\n",
      "        [0.0258, 0.0000, 0.3849, 0.1836, 0.0258, 0.0000, 0.3849, 0.1836, 0.0258,\n",
      "         0.0000, 0.3849, 0.1836]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 합치기\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2240, 0.0000, 0.9753, 0.1161],\n",
      "        [0.3348, 0.0000, 0.0995, 0.0501],\n",
      "        [0.0473, 0.0000, 0.1144, 0.5100],\n",
      "        [0.0258, 0.0000, 0.3849, 0.1836]]) \n",
      "\n",
      " tensor([[1.0149, 0.1779, 0.1814, 0.4025],\n",
      "        [0.1779, 0.1245, 0.0528, 0.0561],\n",
      "        [0.1814, 0.0528, 0.2754, 0.1389],\n",
      "        [0.4025, 0.0561, 0.1389, 0.1825]]) \n",
      "\n",
      " tensor([[5.0171e-02, 0.0000e+00, 9.5130e-01, 1.3477e-02],\n",
      "        [1.1210e-01, 0.0000e+00, 9.9054e-03, 2.5092e-03],\n",
      "        [2.2406e-03, 0.0000e+00, 1.3090e-02, 2.6006e-01],\n",
      "        [6.6640e-04, 0.0000e+00, 1.4815e-01, 3.3718e-02]])\n"
     ]
    }
   ],
   "source": [
    "# 산술 연산\n",
    "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\n",
    "# ``tensor.T`` 는 텐서의 전치(transpose)를 반환합니다.\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "\n",
    "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "\n",
    "\n",
    "print(tensor, \"\\n\\n\", y1, \"\\n\\n\", z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0659) 3.065906524658203 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg, agg_item, type(agg_item))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
