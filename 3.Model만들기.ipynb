{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 만들기\n",
    "\n",
    "<ul>\n",
    "<li>nn.Modeule 클래스를 상속하여 모델 클래스를 정의하는 방법</li>\n",
    "<ul><li>명시적으로 forward() 메서드를 정의해야 함</li>\n",
    "</ul>\n",
    "<li>nn.Seqential 클래스를 사용하여 모델을 정의하는 방법</li>\n",
    "<ul><li>자동으로 순차적으로 레이어들이 연결되어 순전파 동작이 정의됨</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Module 클래스를 상속하여 모델 클래스를 정의하는 방법\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # 모델의 레이어들을 정의하고 초기화\n",
    "        # nn.Sequential을 사용하여 레이어들을 조합\n",
    "        self.layer1 = nn.Linear(784, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(256, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 모델의 순전파 동작을 구현\n",
    "        # nn.Sequential로 정의한 레이어들의 순전파 동작이 자동으로 수행됨\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential 클래스를 사용하여 모델을 정의하는 방법\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.BatchNorm1d\n",
    "- Pytorch의 정규화 모듈 - 배치 정규화(입력 데이터를 평균과 표준편차로 정규화 -> 모델이 더 잘 수렴하도록 도움)를 수행하는데 사용\n",
    "- 1차원 입력에 대해서만 정규화 수행\n",
    "- 생성자에서 num_features인자를 받음 - 입력 데이터의 채널 수\n",
    "<br>\n",
    "<br>\n",
    "<code>torch.nn.BatchNorm1d(num_features=10)</code>은 10개의 채널을 가지는 입력 데이터에 대해서 배치 정규화를 수행하는 BatchNorm1d 모듈을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>torch.nn.BatchNorm1d(num_feature, eps=1e-05, momentum=0.1, affine=True, trach_running_stats=True)</code>\n",
    "- num_features : 입력 데이터의 채널 수를 지정하는 인자, 반드시 지정\n",
    "- eps : 분모에 더해지는 작은 값, 0으로 나누는 것을 방지하기 위한 인자(기본값 : 1e-05)\n",
    "- momentum: 이전 배치의 평균과 분산값을 얼마나 반영할지를 지정한느 인자(기본값 : 0.1)\n",
    "- affine : 정규화된 값을 확대 및 이동시킬지 여부를 지정하는 인자(기본값 : True)\n",
    "- trach_running_stats : 배치 정규화의 효과를 추적할지 여부를 지정하는 인자(기본값 : True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 모델은 입력값을 받아 각 층을 거쳐 출력값을 계산산\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.bn = nn.BatchNorm1d(num_features = 50) # 은닉층의 출력에 배치 정규화를 적용 -> 학습이 더 잘 일어남\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### nn.BatchNorm2d\n",
    "- Pytorch의 정규화 모듈 - 배치 정규화(입력 데이터를 평균과 표준편차로 정규화 -> 모델이 더 잘 수렴하도록 도움)를 수행하는데 사용\n",
    "- 2차원 입력에 대한 배치 정규화 수행\n",
    "<br><br>\n",
    "<code>torch.nn.BatchNorm2d(num_feature, eps=1e-05, momentum=0.1, affine=True, trach_running_stats=True)</code>\n",
    "- num_features : 입력 데이터의 채널 수를 지정하는 인자, 반드시 지정\n",
    "- eps : 분모에 더해지는 작은 값, 0으로 나누는 것을 방지하기 위한 인자(기본값 : 1e-05)\n",
    "- momentum: 이전 배치의 평균과 분산값을 얼마나 반영할지를 지정한느 인자(기본값 : 0.1)\n",
    "- affine : 정규화된 값을 확대 및 이동시킬지 여부를 지정하는 인자(기본값 : True)\n",
    "- trach_running_stats : 배치 정규화의 효과를 추적할지 여부를 지정하는 인자(기본값 : True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm2d = nn.BatchNorm2d(num_features = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Conv1d : 1차원 컨볼루션 레이어를 정의 - 입력 데이터의 한 방향(주로 시계열 데이터에서는 시간 축)으로 컨볼루션 연산을 수행\n",
    "\n",
    "<code>torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride = 1, padding = 0, dilation = 1, groups = 1, bias = True, padding_mode = 'zeros')</code>\n",
    "- in_channels : 입력 데이터의 채널 개수(ex. 입력데이터가 RGB 이미지인 경우 3)\n",
    "- out_channels : 출력 데이터의 채널 개수(컨볼루션 필터의 개수를 의미), 출력 데이터가 몇 개의 특징 맵으로 변환되는 지를 결정\n",
    "- kernel_size : 컨볼루션 필터(커널)의 크기(정수/튜플 형태)<ul><li>ex. kernel_size=3은 3개의 연속된 입력 값에 대해 컨볼루션 연산을 수행, kernel_size(3,5)는 3개의 연속된 입력 값에 대해 한 방향으로 5개의 컨볼루션 연산을 수행</li></ul>\n",
    "- stride : 컨볼루션 필터의 이동 간격(정수/튜플 형태)<ul><li>ex. stride=1은 한 칸씩 이동하면서 컨볼루션 연산을 수행, stride=2는 두 칸씩 이동하면서 컨볼루션 연산을 수행</li></ul>\n",
    "- padding : 입력 데이터에 대해 가상의 패딩을 추가, 컨볼루션 연산의 경계 효과를 조절(정수/튜플 형태)<ul><li>ex. padding=1은 입력 데이터에 한 칸의 패딩을 추가, padding=(1,2)는 입력 데이터에 한 방향으로 한 칸의 패딩을 추가하고 다른 방향으로 두 칸의 패딩을 추가</li></ul>\n",
    "- dilation : 컨볼루션 필터 내의 값 사이의 간격을 조절, 더 넓은 영역을 감지(정수/튜플 형태)\n",
    "- groups : 입력 데이터와 출력 데이터의 채널을 그룹화하여 연산을 수행, 다양한 네트워크 아키텍처를 구성하는데 사용 \n",
    "- bias : 편향 사용 여부를 결정(기본값 : True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size :  torch.Size([16, 16, 100])\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터의 크기가 (16, 3, 100)인 1차원 컨볼루션 레이어를 정의하고, 입력 데이터를 생성한 후 컨볼루션 연산을 수행\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 입력 데이터의 크기 : (배치 크기, 채널, 시퀀스 길이)\n",
    "input_size = (16, 3, 100)\n",
    "\n",
    "# 1차원 컨볼루션 레이어 정의\n",
    "conv1d = nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# 입력 데이터 생성\n",
    "input_data = torch.randn(input_size)\n",
    "\n",
    "# 컨볼루션 연산 수행\n",
    "output = conv1d(input_data)\n",
    "\n",
    "# 출력 데이터의 크기 : (배치 크기, 출력 채널, 출력 시퀀스 길이)\n",
    "print(\"Output size : \", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Conv2d : 2차원 컨볼루션 레이어를 정의 - 이미지나 2D 데이터의 특징 추출에 주로 사용\n",
    "\n",
    "<code>torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride = 1, padding = 0, dilation = 1, groups = 1, bias = True)</code>\n",
    "- in_channels : 입력 데이터의 채널 개수(ex. 입력데이터가 RGB 이미지인 경우 3)\n",
    "- out_channels : 출력 데이터의 채널 개수(컨볼루션 필터의 개수를 의미), 출력 데이터가 몇 개의 특징 맵으로 변환되는 지를 결정<br>-> 값이 클수록 더 복잡한 특징을 학습할 수 잇지만 모델의 파라미터 수가 증가\n",
    "- kernel_size : 컨볼루션 필터(커널)의 크기(정수/튜플 형태)<ul><li>ex. kernel_size=3은 3개의 연속된 입력 값에 대해 컨볼루션 연산을 수행, kernel_size(3,5)는 3개의 연속된 입력 값에 대해 한 방향으로 5개의 컨볼루션 연산을 수행</li></ul>\n",
    "- stride : 컨볼루션 필터의 이동 간격(정수/튜플 형태)<ul><li>ex. stride=1은 한 칸씩 이동하면서 컨볼루션 연산을 수행, stride=2는 두 칸씩 이동하면서 컨볼루션 연산을 수행</li></ul>\n",
    "- padding : 입력 데이터에 대해 가상의 패딩을 추가, 컨볼루션 연산의 경계 효과를 조절(정수/튜플 형태)<ul><li>ex. padding=1은 입력 데이터에 한 칸의 패딩을 추가, padding=(1,2)는 입력 데이터에 한 방향으로 한 칸의 패딩을 추가하고 다른 방향으로 두 칸의 패딩을 추가</li></ul>\n",
    "- dilation : 컨볼루션 필터 내의 값 사이의 간격을 조절, 더 넓은 영역을 감지(정수/튜플 형태)\n",
    "- groups : 입력 데이터와 출력 데이터의 채널을 그룹화하여 연산을 수행, 다양한 네트워크 아키텍처를 구성하는데 사용 <br>값이 크면 채널 간의 관련성을 줄이는 효과\n",
    "- bias : 편향 사용 여부를 결정(기본값 : True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size :  torch.Size([64, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터의 크기가 (64, 3, 32, 32)인 4D 텐서를 입력으로 받아, 3개의 입력 채널을 64개의 출력 채널로 변환하는 컨볼루션 연산을 수행\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 입력 데이터의 크기 : (배치 크기, 채널, 높이, 너비)\n",
    "input_size = (64, 3, 32, 32)\n",
    "\n",
    "# 1차원 컨볼루션 레이어 정의\n",
    "conv1d = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# 입력 데이터 생성\n",
    "input_data = torch.randn(input_size)\n",
    "\n",
    "# 컨볼루션 연산 수행\n",
    "output = conv1d(input_data)\n",
    "\n",
    "# 출력 데이터의 크기 : (배치 크기, 출력 채널, 출력 시퀀스 길이)\n",
    "print(\"Output size : \", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Flatten() : PyTorch의 텐서를 1차원으로 평탄화 -> 다층 퍼셉트론 등의 신경망 레이어에 입력으로 제공 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크기가 (batch_size, num_channels, height, width)인 4차원 입력 텐서를 평탄화하여 1차원으로 변환\n",
    "x = torch.randn(batch_size, num_channels, height, width)\n",
    "flatten = nn.Flatten()\n",
    "x_flatten = flatten(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Linear() : 2개의 행렬 가중치와 편향을 학습하며, 입력 텐서를 선형 변환하여 출력 텐서를 생성\n",
    "<code>nn.Linear(in_features, out_features, bias)</code>\n",
    "- in_features(int) : 입력 텐서의 크기(차원, 특성의 수)\n",
    "- out_features(int) : 출력 텐서의 크기(차원, 특성의 수)\n",
    "- bias(bool, optional) : 편향을 사용할 지 여부(기본값 : True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Tensor :  tensor([[ 0.8696,  0.6732, -1.3565,  1.7093, -0.3729, -1.0334,  0.0570,  0.1954,\n",
      "         -1.5023,  0.9461]]) Input Tensor Size:  torch.Size([1, 10])\n",
      "Output Tensor :  tensor([[-0.4326, -0.0047,  0.1956, -0.4480, -0.3607, -0.0627,  0.7353,  1.3083,\n",
      "          1.1976, -0.0391,  0.1911,  0.9823,  0.0405, -0.1028, -0.0911, -0.1596,\n",
      "          0.2226, -0.8686,  0.0452, -1.0678]], grad_fn=<AddmmBackward0>) Output Tensor Size:  torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 입력 텐서의 크기가 10이고 출력 텐서의 크기가 20인 선형 변환을 수행하는 nn.Linear 모듈 생성\n",
    "linear = nn.Linear(10, 20)\n",
    "\n",
    "# 입력 텐서 생성(크기가 10인 벡터)\n",
    "input_tensor = torch.randn(1, 10)\n",
    "\n",
    "# 선형 변환 수행(입력 텐서를 출력 텐서로 변환)\n",
    "output_tensor = linear(input_tensor)\n",
    "\n",
    "print(\"Output Tensor : \", input_tensor, \"Input Tensor Size: \", input_tensor.size())\n",
    "print(\"Output Tensor : \", output_tensor, \"Output Tensor Size: \", output_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.MaxPool1d : 1차원(Max Pooling) 최대 풀링 연산을 수행하는 클래스\n",
    "Max 풀링은 피처 맵(Feature map)의 공간 차원을 줄이는 역할<br>=> 컨볼루션 연산을 통해 추출된 특징들을 압축하고, 불필요한 정보를 줄이는 효과\n",
    "\n",
    "<code>nn.MaxPool1d(kernel_size, stride, padding)</code>\n",
    "- kernel_size : 풀링 윈도우의 크기를 나타내는 정수 값 또는 튜플<br>\n",
    "입력 신호에서 추출할 최대값을 결정하는데 사용\n",
    "- strid : 풀링 윈도우의 이동 간격을 나타내는 정수 값 또는 튜플<br>\n",
    "풀링 연산의 겹침(overlapping)을 조절하며, 일반적으로 kernel_size와 같은 값을 사용\n",
    "- padding : 입력 신호 주위에 추가할 패딩(padding)의 크기를 나타내는 정수 값 또는 튜플<br>패딩은 입력 신호의 경계 부분에서 풀링 윈도우가 넘어갈 때 발생하는 정보 손실을 줄이는 역할(기본값 : 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Tensor :  tensor([[[-0.5552, -0.6663, -0.2032,  0.0165, -1.7833, -0.6803, -0.5553,\n",
      "          -1.5209, -1.8043,  1.2375]]]) Input Tensor Size:  torch.Size([1, 1, 10])\n",
      "Output Tensor :  tensor([[[-0.5552,  0.0165, -0.6803, -0.5553,  1.2375]]]) Output Tensor Size:  torch.Size([1, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 입력 텐서 생성 (배치 크기: 1, 채널: 1, 시퀀스 길이: 10)\n",
    "input_tensor = torch.randn(1, 1, 10)\n",
    "\n",
    "# MaxPool1d 인스턴스 생성\n",
    "maxpool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "# kernel_size를 2로 설정하여 2개의 연속된 값 중 최대 값을 선택하는 최대 풀링을 수행\n",
    "# stride를 2로 설정하여 폴링 윈도우를 2개의 값씩 이동하며 수행\n",
    "\n",
    "# 최대 풀링 수행\n",
    "output_tensor = maxpool(input_tensor)\n",
    "\n",
    "# 입력 텐서와 출력 텐서의 크기 확인\n",
    "print(\"Output Tensor : \", input_tensor, \"Input Tensor Size: \", input_tensor.size())\n",
    "print(\"Output Tensor : \", output_tensor, \"Output Tensor Size: \", output_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.ModuleList : 파이토치에서 사용되는 모듈들을 리스트 형태로 관리하는 클래스\n",
    "동적으로 모듈들을 추가하거나 삭제 가능<br><br>\n",
    "nn.ModuleList는 파이토치 모델의 서브 모듈(sub-module)들을 리스트 형태로 정의하고, 해당 리스트를 모델 클래스의 속성으로 사용<br>이렇게 정의된 nn.ModuleList는 자동으로 모델의 파라미터들과 함께 관리되며, 모델의 forward 연산에서 호출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(5):\n",
    "            self.linears.append(nn.Linear(10, 20))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.linears:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.ReLU : 파이토치에서 사용되는 ReLU 활성화 함수를 구현한 클래스\n",
    "<code>nn.ReLU(inplace = False)</code>\n",
    "- inplace : ReLU함수의 연산을 in-place로 수행 -> 입력 텐서의 원본을 수정, 연산 속도 향상(기본값 : False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([-0.5873,  0.9109, -1.5854, -1.8586,  0.4784])\n",
      "after ReLU()\n",
      "x:  tensor([-0.5873,  0.9109, -1.5854, -1.8586,  0.4784])\n",
      "y:  tensor([0.0000, 0.9109, 0.0000, 0.0000, 0.4784])\n",
      "------------------------------------------------------------\n",
      "x:  tensor([-1.2202,  0.7015, -0.9940,  0.7418,  0.4913])\n",
      "after ReLU(inplace=True)\n",
      "x:  tensor([0.0000, 0.7015, 0.0000, 0.7418, 0.4913])\n",
      "y:  tensor([0.0000, 0.7015, 0.0000, 0.7418, 0.4913])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ReLU 레이어 인스턴스화\n",
    "relu = nn.ReLU()  # inplace=False가 기본값\n",
    "\n",
    "# ReLU 연산 적용\n",
    "x = torch.randn(5)\n",
    "print('x: ',x)\n",
    "y = relu(x)  # 원본 x는 수정되지 않고, 새로운 텐서 y를 반환\n",
    "print('after ReLU()')\n",
    "print('x: ',x)\n",
    "print('y: ',y)\n",
    "print('-'*60)\n",
    "\n",
    "# inplace=True로 설정한 ReLU 연산\n",
    "x = torch.randn(5)\n",
    "print('x: ',x)\n",
    "relu_inplace = nn.ReLU(inplace=True)\n",
    "y = relu_inplace(x)  # 원본 x가 직접 수정\n",
    "print('after ReLU(inplace=True)')\n",
    "print('x: ',x)\n",
    "print('y: ',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### nn.LeakyReLU :  ReLU 함수와 유사하지만, 입력값이 음수일 때 기울기를 0이 아닌 작은 값으로 유지 -> \"죽은 뉴런(dead neuron)\" 문제를 완화\n",
    "<code>nn.LeakyReLU(negative_slope= , inplace=False)</code>\n",
    "- negative_slope : 입력값이 음수일 때 사용할 기울기 값을 결정(보통 0.01이나 0.2같이 작은 값, 기본값 : 0.01)\n",
    "- inplace : ReLU함수의 연산을 in-place로 수행 -> 입력 텐서의 원본을 수정, 연산 속도 향상(기본값 : False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
